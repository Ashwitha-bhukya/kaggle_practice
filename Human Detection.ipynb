{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONqYgonWlRlvwIAyN0DuoU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashwitha-bhukya/practice_projects/blob/main/Human%20Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "import argparse"
      ],
      "metadata": {
        "id": "8kkTSIqPTnvX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hog = cv2.HOGDescriptor()\n",
        "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())"
      ],
      "metadata": {
        "id": "Sylal1ZWKmog"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**cv2.HOGDescriptor_getDefaultPeopleDetector()** calls the pre-trained model for Human detection of OpenCV and then we will feed our support vector machine with it."
      ],
      "metadata": {
        "id": "aQv34pAoW5HV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, the actual magic will happen.\n",
        "\n",
        "Video: A video combines a sequence of images to form a moving picture. We call these images as Frame. So in general we will detect the person in the frame. And show it one after another that it looks like a video.\n",
        "\n",
        "That is exactly what our Detect() method will do.  It will take a frame to detect a person in it. Make a box around a person and show the frame..and return the frame with person bounded by a green box."
      ],
      "metadata": {
        "id": "TZEstDkGLyzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect(frame):\n",
        "    bounding_box_cordinates, weights =  HOGCV.detectMultiScale(frame, winStride = (4, 4), padding = (8, 8), scale = 1.03)\n",
        "\n",
        "    person = 1\n",
        "    for x,y,w,h in bounding_box_cordinates:\n",
        "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
        "        cv2.putText(frame, f'person {person}', (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)\n",
        "        person += 1\n",
        "\n",
        "    cv2.putText(frame, 'Status : Detecting ', (40,40), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
        "    cv2.putText(frame, f'Total Persons : {person-1}', (40,70), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
        "    cv2.imshow('output', frame)\n",
        "    return frame"
      ],
      "metadata": {
        "id": "oPA16hluK4Ea"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything will be done by detectMultiScale(). It returns 2-tuple.\n",
        "\n",
        "1.List containing Coordinates of bounding Box of person.\n",
        "Coordinates are in form X, Y, W, H.\n",
        "Where x,y are starting coordinates of box and w, h are width and height of box respectively.\n",
        "\n",
        "2.Confidence Value that it is a person.\n",
        "\n",
        "Now, We have our detect method. Let’s Create a Detector."
      ],
      "metadata": {
        "id": "4ghM81MdeBmh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HumanDetectorMethod()**\n",
        "\n",
        "There are two ways of getting Video.\n",
        "\n",
        "1.Web Camera\n",
        "\n",
        "2.Path of file stored\n",
        "\n",
        "In this deep learning project, we can take images also. So our method will check if a path is given then search for the video or image in the given path and operate. Otherwise, it will open the webCam."
      ],
      "metadata": {
        "id": "_ZYvqroKfcyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def humanDetector(args):\n",
        "    image_path = args[\"image\"]\n",
        "    video_path = args['video']\n",
        "    if str(args[\"camera\"]) == 'true' : camera = True\n",
        "    else : camera = False\n",
        "\n",
        "    writer = None\n",
        "    if args['output'] is not None and image_path is None:\n",
        "        writer = cv2.VideoWriter(args['output'],cv2.VideoWriter_fourcc(*'MJPG'), 10, (600,600))\n",
        "\n",
        "    if camera:\n",
        "        print('[INFO] Opening Web Cam.')\n",
        "        detectByCamera(ouput_path,writer)\n",
        "    elif video_path is not None:\n",
        "        print('[INFO] Opening Video from path.')\n",
        "        detectByPathVideo(video_path, writer)\n",
        "    elif image_path is not None:\n",
        "        print('[INFO] Opening Image from path.')\n",
        "        detectByPathImage(image_path, args['output'])"
      ],
      "metadata": {
        "id": "6aoVx4g_fxPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### DetectByCamera()method:\n",
        "\n",
        "def detectByCamera(writer):\n",
        "    video = cv2.VideoCapture(0)\n",
        "    print('Detecting people...')\n",
        "    while True:\n",
        "        check, frame = video.read()\n",
        "        frame = detect(frame)\n",
        "        if writer is not None:\n",
        "            writer.write(frame)\n",
        "        key = cv2.waitKey(1)\n",
        "        if key == ord('q'):\n",
        "            break\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "sxdraSOziCbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**cv2.VideoCapture(0)** passing 0 in this function means we want to record from a webcam. video.read() read frame by frame. It returns a check which is True if this was able to read a frame otherwise False.\n",
        "\n",
        "Now, For each Frame, we will call detect() method. Then we write the frame in our output file"
      ],
      "metadata": {
        "id": "ad20wHb3iiGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###DetectPathVideo()Method:\n",
        "\n",
        "def detectByPathVideo(path, writer):\n",
        "    video = cv2.VideoCapture(path)\n",
        "    check, frame = video.read()\n",
        "    if check == False:\n",
        "        print('Video Not Found. Please Enter a Valid Path (Full path of Video Should be Provided).')\n",
        "        return\n",
        "    print('Detecting people...')\n",
        "    while video.isOpened():\n",
        "        #check is True if reading was successful\n",
        "        check, frame =  video.read()\n",
        "        if check:\n",
        "            frame = imutils.resize(frame , width=min(800,frame.shape[1]))\n",
        "            frame = detect(frame)\n",
        "\n",
        "            if writer is not None:\n",
        "                writer.write(frame)\n",
        "\n",
        "            key = cv2.waitKey(1)\n",
        "            if key== ord('q'):\n",
        "                break\n",
        "        else:\n",
        "            break\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()\n",
        "def detectByCamera(writer):\n",
        "    video = cv2.VideoCapture(0)\n",
        "    print('Detecting people...')\n",
        "    while True:\n",
        "        check, frame = video.read()\n",
        "        frame = detect(frame)\n",
        "        if writer is not None:\n",
        "            writer.write(frame)\n",
        "        key = cv2.waitKey(1)\n",
        "        if key == ord('q'):\n",
        "                break\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "grc_CBNhibW_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The implementation is similar to the previous function except for each frame we will check that it successfully reads the frame or not. At the end when the frame is not read we will end the loop."
      ],
      "metadata": {
        "id": "wFW823r89gbR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DetectByPathImage()Method:**\n",
        "\n",
        "This method is used if a person needs to be detected from an image"
      ],
      "metadata": {
        "id": "tRMPm_ceCFxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detectByPathImage(path, output_path):\n",
        "    image = cv2.imread(path)\n",
        "    image = imutils.resize(image, width = min(800, image.shape[1]))\n",
        "    result_image = detect(image)\n",
        "    if output_path is not None:\n",
        "        cv2.imwrite(output_path, result_image)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "HQdqFXKP9nrR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ArgParse()Method**\n",
        "\n",
        "The function argparse() simply parses and returns as a dictionary the arguments passed through your terminal to our script. There will be Three arguments within the Parser:\n",
        "\n",
        "**1.Image:** The path to the image file inside your system\n",
        "\n",
        "**2.Video:** The path to the Video file inside your system\n",
        "\n",
        "**3.Camera:** A variable that if set to ‘true’ will call the cameraDetect() method."
      ],
      "metadata": {
        "id": "U2PFY1FkEyl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def argsParser():\n",
        "    arg_parse = argparse.ArgumentParser()\n",
        "    arg_parse.add_argument(\"-v\", \"--video\", default=None, help=\"path to Video File \")\n",
        "    arg_parse.add_argument(\"-i\", \"--image\", default=None, help=\"path to Image File \")\n",
        "    arg_parse.add_argument(\"-c\", \"--camera\", default=False, help=\"Set true if you want to use the camera.\")\n",
        "    arg_parse.add_argument(\"-o\", \"--output\", type=str, help=\"path to optional output video file\")\n",
        "    args = vars(arg_parse.parse_args())\n",
        "    return args"
      ],
      "metadata": {
        "id": "h_89BhFgE9ew"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Main Function**\n",
        "\n",
        "We have reached the end of our project"
      ],
      "metadata": {
        "id": "fBl7S45BGMCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    HOGCV = cv2.HOGDescriptor()\n",
        "    HOGCV.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
        "    args = argsParser()\n",
        "    humanDetector(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "q1r_cg0JGXrv",
        "outputId": "2fc3a955-8ed2-4117-9447-102f7f92d6e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [-v VIDEO] [-i IMAGE] [-c CAMERA]\n",
            "                             [-o OUTPUT]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-8f933cf4-bb0a-4878-935d-29f21878b018.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of declaring our model above, we can declare it in our main function."
      ],
      "metadata": {
        "id": "1eqPSSX8ORYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run the Human Detection Project**\n",
        "\n",
        "To run the human detection deep learning project, please run below-mentioned commands as per requirements"
      ],
      "metadata": {
        "id": "YFs1s4RmOTOf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. To give video file as input:"
      ],
      "metadata": {
        "id": "0F-kUot6OdVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python main.py -v ‘Path_to_video’"
      ],
      "metadata": {
        "id": "toP9-OOyOtmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. To give Image file as input:"
      ],
      "metadata": {
        "id": "nPL-_PMpOu2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python main.py -i ‘Path_to-image’"
      ],
      "metadata": {
        "id": "-EbiJmSQO159"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. To use the camera:"
      ],
      "metadata": {
        "id": "P189CwBwO52i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python main.py -c True"
      ],
      "metadata": {
        "id": "BP_DYqOqO_3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. To save the output:"
      ],
      "metadata": {
        "id": "D8VQI6smPCxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Python main.py -c True -o ‘file_name’"
      ],
      "metadata": {
        "id": "nAH_vQPyPO6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Output**\n",
        "\n",
        "Now, after running the human detection python project with multiple images and video, we will get:"
      ],
      "metadata": {
        "id": "fUba-AnYPXRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary**\n",
        "In this deep learning project, we have learned how to create a people counter using HOG and OpenCV to generate an efficient people counter. We developed the project where you can supply the input as: video, image, or even live camera. This is an intermediate level project, which will surely help you in mastering python and deep learning libraries."
      ],
      "metadata": {
        "id": "kVRlEidtPaXR"
      }
    }
  ]
}